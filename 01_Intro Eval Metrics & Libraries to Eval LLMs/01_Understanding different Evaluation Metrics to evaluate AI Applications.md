# ğŸ“Š Evaluation Metrics per LLM 

> Lezione dedicata alla comprensione delle **metriche di valutazione (evaluation metrics)** nei sistemi basati su modelli linguistici di grandi dimensioni (LLM).  
> ğŸ“… Data: 2025-04-15

---

## ğŸ“Œ Introduzione

Le **metriche di valutazione** sono strumenti fondamentali per misurare le prestazioni di un LLM o di un'applicazione costruita su di esso, soprattutto nel contesto di:
- RAG (Retrieval-Augmented Generation)
- Tool-augmented LLMs (funzioni e agenti)
- Chatbot conversazionali

---

## ğŸ§© Metriche piÃ¹ comuni

### 1. âœ… Answer Relevance
- **Definizione**: misura quanto la risposta del modello Ã¨ pertinente alla query dellâ€™utente.
- **Applicazione**: valida sia su modelli LLM base che su applicazioni AI.
- **Obiettivo**: garantire che la risposta rifletta davvero lâ€™intento dellâ€™utente.

---

### 2. ğŸ”„ Contextual Relevancy and Contextual Precision
#### a. Contextual Relevancy
- **Definizione**: verifica se la risposta si allinea al contesto recuperato (es. in un sistema RAG).
- **Domanda chiave**: la risposta usa correttamente il contesto fornito?

#### b. Contextual Precision
- **Definizione**: misura quanto Ã¨ preciso il contesto recuperato.
- **Domanda chiave**: il contesto Ã¨ rilevante rispetto alla query?

ğŸ“Œ *Differenza*: una valuta **la qualitÃ  della risposta rispetto al contesto**, lâ€™altra valuta **la qualitÃ  del contesto stesso**.

---

### 3. ğŸ§° Tool Selection Accuracy
- **Definizione**: valuta la capacitÃ  del LLM di selezionare il giusto tool da eseguire per una determinata richiesta.
- **Contesto**: cruciale in sistemi con decine o centinaia di strumenti.
- **Esempio**: distinguere quando usare un tool di invio email o di interrogazione database.

---

### 4. âš–ï¸ Bias Detection
- **Definizione**: identifica eventuali bias nei contenuti generati.
- **Esempio**: se alla domanda â€œI ragazzi prendono voti piÃ¹ alti delle ragazze?â€ il modello risponde â€œSÃ¬â€, allora Ã¨ presente un bias.
- **Importanza**: i bias riflettono pregiudizi nei dati di addestramento.

---

### 5. ğŸ§® Function Argument Accuracy
- **Definizione**: verifica la correttezza degli argomenti passati da un LLM a una funzione o API.
- **Applicazione**: fondamentale quando lâ€™LLM interagisce con tool e funzioni esterne.
- **Effetti**: un argomento errato puÃ² causare il fallimento della chiamata e risposte nulle o sbagliate.

---

## ğŸ§  Altre metriche citate (in base agli strumenti usati)

- **Faithfulness**: la risposta Ã¨ supportata dal contesto?
- **Hallucination Detection**: presenza di informazioni inventate.
- **Completeness**: la risposta Ã¨ esaustiva?
- **Context Recall**: quanto contesto rilevante Ã¨ stato effettivamente utilizzato?
- **Function Call Accuracy**: la funzione invocata Ã¨ quella corretta?

---

## ğŸ› ï¸ Nota sugli strumenti

Non tutti gli strumenti di valutazione supportano tutte le metriche.  
Alcuni hanno funzioni avanzate come **hallucination detection**, altri no.

---

## âœ… Conclusione

Queste metriche:
- Consentono di valutare in profonditÃ  **l'affidabilitÃ , l'efficacia e la correttezza** di un LLM o del sistema che lo utilizza.
- Sono essenziali per il debugging, il miglioramento continuo e lâ€™auditabilitÃ  delle risposte AI.

