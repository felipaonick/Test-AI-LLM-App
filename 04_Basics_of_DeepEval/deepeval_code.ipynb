{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import deepeval\n",
    "deepeval.login_with_confident_api_key(api_key=\"jHNUlDhc0dZumi5cgmSW2ea5GM4W9gSu4/c1uyS4YzI=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Carica variabili da .env nel tuo ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing simple DeepEval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\felip\\Desktop\\import-pc\\Test_AI_&amp;_LLM_App\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\felip\\Desktop\\import-pc\\Test_AI_&_LLM_App\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "answer_relevancy_metric = AnswerRelevancyMetric()\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Who is the current president of the United States of America?\",\n",
    "    actual_output=\"Joe Biden\",\n",
    "    retrieval_context=[\"Joe Biden is the current president of the United States of America.\"]\n",
    ")\n",
    "\n",
    "# Usa il modello gpt-4 di OpenAI con la api key per ottenera la misurazione\n",
    "answer_relevancy_metric.measure(test_case)\n",
    "\n",
    "print(answer_relevancy_metric.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing LLMs for Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\felip\\Desktop\\import-pc\\Test_AI_&amp;_LLM_App\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\felip\\Desktop\\import-pc\\Test_AI_&_LLM_App\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "\n",
    "# si aspetta anche un expected_output per misurare la precisione\n",
    "contextual_precision_metric = ContextualPrecisionMetric()\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Who is the current president of USA in 2024?\",\n",
    "    # Should come from an LLM or from an Agent or RAG\n",
    "    actual_output=\"Donald Trump\",\n",
    "    # RAG - Vector DB, AI Agent - Agent Tools Call, LLM - LLM invoke response\n",
    "    retrieval_context=[\"Donald Trump serves as the current president of America.\"],\n",
    "    expected_output=\"Donald Trump is the current president of America\"\n",
    ")\n",
    "\n",
    "# usa gpt-4o di openai con la api key per ottenere la misurazione\n",
    "contextual_precision_metric.measure(test_case=test_case)\n",
    "\n",
    "\n",
    "print(contextual_precision_metric.score)\n",
    "print(contextual_precision_metric.success)\n",
    "print(contextual_precision_metric.score_breakdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaluationDataSet to evaluate our Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "answer_relevancy_metric = AnswerRelevancyMetric()\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Who is the current president of the United States of America?\",\n",
    "    actual_output=\"Joe Biden\",\n",
    "    retrieval_context=[\"Joe Biden serves as the current president of America.\"]\n",
    ")\n",
    "\n",
    "dataset = EvaluationDataset(test_cases=[test_case])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(test_cases=[LLMTestCase(input='Who i sthe current president of the United States of America?', actual_output='Joe Biden', expected_output=None, context=None, retrieval_context=['Joe Biden serves as the current president of America.'], additional_metadata=None, comments=None, tools_called=None, expected_tools=None, reasoning=None, token_cost=None, completion_time=None, name=None)], goldens=[], conversational_goldens=[], _alias=None, _id=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|100% (1/1) [Time Taken: 00:12, 12.57s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the answer directly addresses the question without any irrelevant content. Great job!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Who i sthe current president of the United States of America?\n",
      "  - actual output: Joe Biden\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['Joe Biden serves as the current president of America.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cases</span></a><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! View results on \n",
       "\u001b]8;id=444680;https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-cases\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=444680;https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-cases\u001b\\\u001b[4;94mcases\u001b[0m\u001b]8;;\u001b\\\u001b[4;94m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the answer directly addresses the question without any irrelevant content. Great job!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0033725000000000005, verbose_logs='Statements:\\n[\\n    \"Joe Biden.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input='Who i sthe current president of the United States of America?', actual_output='Joe Biden', expected_output=None, context=None, retrieval_context=['Joe Biden serves as the current president of America.'], additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cm9jp4aqy14u4p0fofkp1xgyk/evaluation/test-runs/cm9l6idzw55map0fo85uoyf6c/test-cases')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.evaluate(metrics=[answer_relevancy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
